title: LLM Analysis Quiz Solver
emoji: ğŸƒ
colorFrom: red
colorTo: blue
sdk: docker
pinned: false
app_port: 7860
LLM Analysis â€“ Autonomous Quiz Solver Agent






LLM Analysis is an intelligent, autonomous agent built with LangGraph and LangChain. It is designed to solve data-driven quizzes by orchestrating web scraping, data processing, analysis, and visualization tasks. The system utilizes Googleâ€™s Gemini 2.5 Flash model to manage tool selection and automated decision-making.

ğŸ“‹ Table of Contents

Project Overview

System Architecture

Key Features

Project Structure

Installation

Configuration

Usage

API Endpoints

Available Tools

Docker Deployment

Operational Workflow

Design Considerations

License

ğŸ” Project Overview

This system was developed for the Tools in Data Science (TDS) course project to autonomously solve multi-step quizzes involving:

Data Acquisition: Web scraping, API interactions, file downloads

Data Preparation: Cleaning and structuring text, PDFs, CSVs, and other formats

Data Analysis: Filtering, aggregation, statistical operations, and machine learning integration

Data Visualization: Generating charts, reports, and narrative summaries

The agent accepts quiz URLs via a REST API, navigates through sequential pages, executes tasks using LLM reasoning combined with specialized tools, and submits results to the evaluation server.

ğŸ—ï¸ System Architecture

The system employs a LangGraph state machine architecture:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚  â† Receives POST requests with quiz URLs
â”‚   Server    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent     â”‚  â† LangGraph orchestrator powered by Gemini 2.5 Flash
â”‚   (LLM)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼            â–¼            â–¼             â–¼              â–¼
   [Scraper]   [Downloader]  [Code Exec]  [POST Req]  [Add Deps]

Core Components

FastAPI Server (main.py) â€“ Handles POST requests, validates secrets, and triggers agent execution.

LangGraph Agent (agent.py) â€“ Orchestrates tool usage and manages decision-making through a state machine.

Tools Package (tools/) â€“ Modular tools for scraping, downloading, code execution, API requests, and dependency management.

LLM â€“ Google Gemini 2.5 Flash with a rate limit of nine requests per minute.

âœ¨ Key Features

Autonomous Multi-Step Problem Solving: Sequentially processes multiple quiz pages.

Dynamic JavaScript Rendering: Utilizes Playwright to handle client-side rendered pages.

Python Code Generation & Execution: Automates data processing, analysis, and visualization tasks.

Flexible Data Handling: Supports PDFs, CSVs, images, and other formats.

Self-Installing Dependencies: Automatically installs required Python packages.

Robust Error Handling: Retries failed tasks within defined time limits.

Docker-Ready Deployment: Compatible with cloud platforms including HuggingFace Spaces.

Rate Limiting: Ensures compliance with API quotas using exponential backoff.

ğŸ“ Project Structure
LLM-Analysis-TDS-Project-2/
â”œâ”€â”€ agent.py                     # LangGraph orchestration and state machine
â”œâ”€â”€ main.py                      # FastAPI server with /solve endpoint
â”œâ”€â”€ pyproject.toml               # Project dependencies and configuration
â”œâ”€â”€ Dockerfile                   # Container configuration with Playwright
â”œâ”€â”€ .env                         # Environment variables (not committed)
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ web_scraper.py           # Playwright-based HTML renderer
â”‚   â”œâ”€â”€ code_generate_and_run.py # Python code executor
â”‚   â”œâ”€â”€ download_file.py         # File downloader
â”‚   â”œâ”€â”€ send_request.py          # HTTP POST request handler
â”‚   â””â”€â”€ add_dependencies.py      # Dynamic package installer
â””â”€â”€ README.md

ğŸ“¦ Installation
Prerequisites

Python 3.12 or higher

uv package manager
 (recommended) or pip

Git

Step 1: Clone the Repository
git clone <your-github-link-here>
cd LLM-Analysis-TDS-Project-2

Step 2: Install Dependencies
Option A â€“ Using uv (Recommended)
pip install uv
uv sync
uv run playwright install chromium
uv run main.py

Option B â€“ Using pip
python -m venv venv
.\venv\Scripts\activate       # Windows
# source venv/bin/activate    # macOS/Linux
pip install -e .
playwright install chromium
python main.py


Server will be available at http://0.0.0.0:7860.

âš™ï¸ Configuration
Environment Variables (.env)
EMAIL=your.email@example.com
SECRET=your_secret_string
GOOGLE_API_KEY=your_gemini_api_key_here

Gemini API Key

Navigate to Google AI Studio

Generate a new API key

Insert the key into your .env file

ğŸš€ Usage
Local Development
uv run main.py    # Or use python main.py

Test the POST Endpoint
curl -X POST http://localhost:7860/solve \
  -H "Content-Type: application/json" \
  -d '{
    "email": "your.email@example.com",
    "secret": "your_secret_string",
    "url": "https://tds-llm-analysis.s-anand.net/demo"
  }'


Expected response:

{
  "status": "ok"
}

ğŸŒ API Endpoints
POST /solve

Triggers the autonomous agent.

Request Body:

{
  "email": "your.email@example.com",
  "secret": "your_secret_string",
  "url": "https://example.com/quiz-123"
}


Responses:

Status	Description
200	Secret verified; agent started
400	Invalid JSON payload
403	Invalid secret
GET /healthz

Health monitoring endpoint:

{
  "status": "ok",
  "uptime_seconds": 3600
}

ğŸ› ï¸ Available Tools

Web Scraper (get_rendered_html) â€“ Playwright-based JavaScript rendering

File Downloader (download_file) â€“ Downloads PDFs, CSVs, images, etc.

Code Executor (run_code) â€“ Executes Python scripts in isolation

POST Request (post_request) â€“ Submits JSON payloads to endpoints

Dependency Installer (add_dependencies) â€“ Dynamically installs required packages

ğŸ³ Docker Deployment
docker build -t llm-analysis-agent .
docker run -p 7860:7860 \
  -e EMAIL="your.email@example.com" \
  -e SECRET="your_secret_string" \
  -e GOOGLE_API_KEY="your_api_key" \
  llm-analysis-agent

HuggingFace Spaces Deployment

Create a Docker-based Space

Push this repository

Configure secrets (EMAIL, SECRET, GOOGLE_API_KEY)

Space builds and deploys automatically

ğŸ§  Operational Workflow

FastAPI receives a POST request and validates the secret.

LangGraph agent initializes a state machine.

The agent iteratively:

Analyzes the current quiz page

Executes tools for scraping, downloading, or code execution

Submits answers and verifies correctness

Process continues until no further quiz URLs are available; the agent returns "END".

ğŸ“ Design Considerations

LangGraph Architecture â€“ Enables flexible routing and complex decision-making

Background Processing â€“ Prevents HTTP timeouts

Tool Modularity â€“ Independent testing and debugging

Rate Limiting â€“ Preserves API quotas (9 requests/min for Gemini)

Dynamic Code Execution â€“ Supports complex data operations

Playwright â€“ Handles JavaScript-intensive pages

uv Package Manager â€“ Ensures fast and adaptive dependency management

ğŸ“„ License

This project is licensed under the MIT License. See LICENSE
 for details.

Author: Hana Muhammed
Course: Tools in Data Science (TDS)
Institution: IIT Madras

For questions or issues, please open an issue on the GitHub repository# TDS_Project_2
